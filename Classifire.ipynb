{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Library\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, RepeatedStratifiedKFold\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score,f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "%config InlineBackend.figure_format='retina'\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import export_graphviz\n",
    "from io import StringIO\n",
    "from sklearn import preprocessing\n",
    "from IPython.display import Image\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import statsmodels.api as sm\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Data\n",
    "data=pd.read_excel(\"C:\\Users\\Asus\\OneDrive\\เดสก์ท็อป\\Main folder\\My_Project\\Kmeans_Data_Povertygap.xlsx\")\n",
    "X = data[[ 'x2', 'x3','x5', 'x6', 'x7',  'x10','x12','x13']]\n",
    "y = data[['y']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "#Imbalance Data\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "X_train=X_resampled\n",
    "y_train=y_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Best Parameter From GridSearch\n",
    "best_params_ada = {'learning_rate': 0.1, 'n_estimators': 200}\n",
    "best_gradient_boost_model = {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 50}\n",
    "best_params_XG = {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 100, 'subsample': 0.5}\n",
    "best_params_RF = {'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 200}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Function\n",
    "def calculate_metrics(model, X_train, X_test, y_train, y_test):\n",
    "    train_pred = model.predict(X_train)\n",
    "    test_pred = model.predict(X_test)\n",
    "\n",
    "    accuracy_train = accuracy_score(y_train, train_pred)\n",
    "    accuracy_test = accuracy_score(y_test, test_pred)\n",
    "    precision = precision_score(y_test, test_pred, average='weighted')\n",
    "    recall = recall_score(y_test, test_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, test_pred, average='weighted')\n",
    "    accuracy = accuracy_score(y_test, y_pred) * 100\n",
    "\n",
    "    return accuracy_train, accuracy_test, precision, recall, f1,accuracy\n",
    "\n",
    "# Parameters to adjust to reduce overfitting\n",
    "param_adjustments = {\n",
    "    'AdaBoost': {'learning_rate': [0.05, 0.1, 0.15], 'n_estimators': [100, 150, 200]},\n",
    "    'GradientBoosting': {'learning_rate': [0.01, 0.05, 0.1], 'max_depth': [3, 4, 5], 'n_estimators': [50, 100, 150]},\n",
    "    'XGBoost': {'learning_rate': [0.01, 0.05, 0.1], 'max_depth': [3, 4, 5], 'n_estimators': [50, 100, 150], 'subsample': [0.5, 0.7]},\n",
    "    'RandomForest': {'max_depth': [5, 7, 10], 'min_samples_leaf': [2, 4, 6], 'min_samples_split': [10, 15], 'n_estimators': [100, 150, 200]}\n",
    "}\n",
    "\n",
    "# Variables to store all results\n",
    "results = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
